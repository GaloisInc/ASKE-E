The Problem
-----------

Propose a Level of Effort (LOE) metric to quantify the amount of programming work required to develop a correct implementation of a simulation of an epidemiological model.

The Initial Proposal
--------------------

We propose that LOE is related to program complexity, which in turn is related primarily to the size of the program. To a first approximation, a longer program takes longer to write. The challenge then becomes finding a way to quantify the length of a program in a way that is somewhat predictable despite variations in programmer style and preference, for example the presence or absence of comments and whitespace and use of short versus long identifier names.

The Kolmogorov complexity[1] metric suggests a solution which is independent of choice of representation: find the shortest program which emits the text of the program to be measured. While Kolmogorov complexity is not computable[2], compressibility of the program text serves as an approximate upper bound on the value expected of the the text's Kolmogorov complexity[3,4].

Caveats
-------

Kolmogorov complexity (and our computable proxy: compressibility) considers the entire program text, including comments (which are informative to the reader, but do not contribute to the behavior of the program) and translation directives of various kinds (e.g. compiler directives, pragmas and makefiles). We should always strip comments. It's less clear what to do about translation directives; we will attend to this question after discussions about whether our proposal satisfies the desire for an LOE metric.

Alpha-conversion
----------------

When using compressibility as a proxy for Kolmogorov complexity, the resulting metric is affected strongly affected by identifier length. We address this by renaming user-defined symbols to have the minimum number of characters needed, based upon the number of such symbols in the program. Likewise, while literal strings are essential to the proper function of a program, they do not (absent use of an eval-like function) contribute the the essential complexity of a program; we normalize all strings to a fixed length and content. Symbols which are essential to describe the interpretation of a program, such as library function names and reserved words in the language, are not subjected to alpha-conversion. Keyword argument names are considered an essential part of function invocation and are not subjected to alpha-conversion.

The following table illustrates the significant effect of identifier length upon compressibility and the relative insignificance of the order of appearance of functions in the program text. All of these programs contain the same set of forward declarations of their functions, allowing the functions to be reordered without otherwise changing the program.

```
Minimal-length alpha-converted identifiers
1143	toposort-orig.c
1135	toposort-shuf-1.c
1142	toposort-shuf-2.c
1140	toposort-shuf-3.c
Suffix xy appended to alpha-converted identifiers
1252	toposort-orig.c
1245	toposort-shuf-1.c
1250	toposort-shuf-2.c
1256	toposort-shuf-3.c
Suffix xyz appended to alpha-converted identifiers
1285	toposort-orig.c
1289	toposort-shuf-1.c
1290	toposort-shuf-2.c
1292	toposort-shuf-3.c
Suffix xyzzy appended to alpha-converted identifiers
1351	toposort-orig.c
1352	toposort-shuf-1.c
1348	toposort-shuf-2.c
1345	toposort-shuf-3.c
Suffix xyzzy0987654321 appended to alpha-converted identifiers
1608	toposort-orig.c
1600	toposort-shuf-1.c
1619	toposort-shuf-2.c
1591	toposort-shuf-3.c
```

Other Considerations
--------------------

The implementation of the compression method used as a proxy for Kolmogorov complexity will affect the compressibility metric. This will be particularly true in the case of short program texts, as the size of the dictionary (which is part of the compressed text) may, for example, be padded to some minimum size for the convenience of the decompression algorithm. Additionally, some compression methods are known to emit multiple dictionaries; this can happen when the compressor encounters new text in the input stream and that text is not adequately compressible using the active dictionary[5]. It's not clear how or whether this will affect the compressibility measurement.

Implementations of a given compression method may differ in their encodings while still being considered to be the same method[6]; we don't know how significant these differences may be as regards a compressibility measure.

Other Approaches
----------------

We attempted to apply Latent Semantic Indexing[7] as a measure of document similarity. We thought of this not as LOE for a specific program text, but rather as a measure of the effort required to transform one text into a larger, more complex text (e.g. ODE to RNET or RNET to a discrete event simulation written in a general-purpose programming language). We quickly discovered that the method is not useful when scaled down to using a single document as a corpus.

We considered and rejected the use of edit distance[8] (e.g. Levenshtein distance[9]) to measure document similarity. The edit distance is sensitive to spelling variations; transforming a program by simply renaming all of its identifiers will result in a nonzero edit distance even though the two variations are functionally identical. 

As an adjunct to compressibility, we also count the number of unique tokens (excluding punctuation) in a program text as an indicator of cognitive effort for the programmer; the intuition is that a larger number of unique tokens contributes to an increased LOE.

Results
-------

We collected from the Rosetta Code website[10] a number of sample programs written in C, C++, FORTRAN and Haskell. Some of these samples have been edited for consistency across languages; e.g. to remove test drivers and data leaving only the essential algorithmic code. We also gathered several ODEs with corresponding solvers written in Julia[11] and Python[12]. Comments have been removed from all source texts.

The following table shows the analysis of the sample source codes.

```
    Source text   proxy K(s)  Unique syms  K(s)/U(s)
        hello.c           55            6       9.16
      hello.cpp           83           10       8.30
      hello.f90           69            7       9.85
       hello.hs           29            3       9.66
    quicksort.c          213           21      10.14
  quicksort.cpp          293           23      12.73
  quicksort.f90          585           38      15.39
   quicksort.hs           77            8       9.62
     toposort.c          731           52      14.05
   toposort.cpp          739           57      12.96
   toposort.f90          409           30      13.63
    toposort.hs          515           56       9.19
    ackermann.c          101            7      14.42
  ackermann.cpp          131            9      14.55
  ackermann.f90          173           14      12.35
   ackermann.hs           88            8      11.00
      ode-1.txt           55            8       6.87
       ode-1.jl          204           25       8.16
     ode-1_1.py          267           35       7.62
     ode-1_2.py          311           32       9.71
     ode-1_3.py          231           28       8.25
     ode-1_4.py          243           29       8.37
     ode-1_5.py          569           63       9.03
      ode-2.txt           78           12       6.50
       ode-2.jl          314           44       7.13
     ode-2_1.py          320           47       6.80
     ode-2_2.py          353           42       8.40
     ode-2_3.py          300           42       7.14
     ode-2_4.py          333           44       7.56
     ode-2_5.py          663           73       9.08
      ode-3.txt           50            8       6.25
       ode-3.jl          248           33       7.51
     ode-3_1.py          301           44       6.84
     ode-3_2.py          350           41       8.53
     ode-3_3.py          293           41       7.14
     ode-3_4.py          311           43       7.23
     ode-3_5.py          569           63       9.03
```

References
----------

```
[1] https://en.wikipedia.org/wiki/Kolmogorov_complexity
[2] https://en.wikipedia.org/wiki/Kolmogorov_complexity#Uncomputability_of_Kolmogorov_complexity
[3] https://en.wikipedia.org/wiki/Kolmogorov_complexity#Compression
[4] https://en.wikipedia.org/wiki/Lempel-Ziv_complexity
[5] ? - streaming compression dictionary update
[6] https://en.wikipedia.org/wiki/LZ77_and_LZ78
[7] https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing
[8] https://en.wikipedia.org/wiki/Edit_distance
[9] https://en.wikipedia.org/wiki/Levenshtein_distance
[10] https://rosettacode.org/
[11] https://computationalmindset.com/en/neural-networks/ordinary-differential-equation-solvers-in-julia.html
[12] https://computationalmindset.com/en/neural-networks/ordinary-differential-equation-solvers.html
```

Appendix
--------

This is all of the sample code:

```


                      bounds/toposort-orig.c


#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
 
int get_item(item *list, int *len, const char *name);
void add_dep(item it, int i);
int parse_input(item *ret);
int get_depth(item list, int idx, int bad);
int main();

char input[] =
	"des_system_lib   std synopsys std_cell_lib des_system_lib dw02 dw01 ramlib ieee\n"
	"dw01             ieee dw01 dware gtech\n"
	"dw02             ieee dw02 dware\n"
	"dw03             std synopsys dware dw03 dw02 dw01 ieee gtech\n"
	"dw04             dw04 ieee dw01 dware gtech\n"
	"dw05             dw05 ieee dware\n"
	"dw06             dw06 ieee dware\n"
	"dw07             ieee dware\n"
	"dware            ieee dware\n"
	"gtech            ieee gtech\n"
	"ramlib           std ieee\n"
	"std_cell_lib     ieee std_cell_lib\n"
	"synopsys\n"
	"cycle_11	  cycle_12\n"
	"cycle_12	  cycle_11\n"
	"cycle_21	  dw01 cycle_22 dw02 dw03\n"
	"cycle_22	  cycle_21 dw01 dw04";
 
typedef struct item_t item_t, *item;
struct item_t { const char *name; int *deps, n_deps, idx, depth; };
 
int get_item(item *list, int *len, const char *name)
{
	int i;
	item lst = *list;
 
	for (i = 0; i < *len; i++)
		if (!strcmp(lst[i].name, name)) return i;
 
	lst = *list = realloc(lst, ++*len * sizeof(item_t));
	i = *len - 1;
	memset(lst + i, 0, sizeof(item_t));
	lst[i].idx = i;
	lst[i].name = name;
	return i;
}
 
void add_dep(item it, int i)
{
	if (it->idx == i) return;
	it->deps = realloc(it->deps, (it->n_deps + 1) * sizeof(int));
	it->deps[it->n_deps++] = i;
}
 
int parse_input(item *ret)
{
	int n_items = 0;
	int i, parent, idx;
	item list = 0;
 
	char *s, *e, *word, *we;
	for (s = input; ; s = 0) {
		if (!(s = strtok_r(s, "\n", &e))) break;
 
		for (i = 0, word = s; ; i++, word = 0) {
			if (!(word = strtok_r(word, " \t", &we))) break;
			idx = get_item(&list, &n_items, word);
 
			if (!i) parent = idx;
			else    add_dep(list + parent, idx);
		}
	}
 
	*ret = list;
	return n_items;
}
 
int get_depth(item list, int idx, int bad)
{
	int max, i, t;
 
	if (!list[idx].deps)
		return list[idx].depth = 1;
 
	if ((t = list[idx].depth) < 0) return t;
 
	list[idx].depth = bad;
	for (max = i = 0; i < list[idx].n_deps; i++) {
		if ((t = get_depth(list, list[idx].deps[i], bad)) < 0) {
			max = t;
			break;
		}
		if (max < t + 1) max = t + 1;
	}
	return list[idx].depth = max;
}
 
int main()
{
	int i, j, n, bad = -1, max, min;
	item items;
	n = parse_input(&items);
 
	for (i = 0; i < n; i++)
		if (!items[i].depth && get_depth(items, i, bad) < 0) bad--;
 
	for (i = 0, max = min = 0; i < n; i++) {
		if (items[i].depth > max) max = items[i].depth;
		if (items[i].depth < min) min = items[i].depth;
	}
 
	printf("Compile order:\n");
	for (i = min; i <= max; i++) {
		if (!i) continue;
 
		if (i < 0) printf("   [unorderable]");
		else	   printf("%d:", i);
 
		for (j = 0; j < n || !putchar('\n'); j++)
			if (items[j].depth == i)
				printf(" %s", items[j].name);
	}
 
	return 0;
}


                     bounds/toposort-shuf-1.c


#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
 
int get_item(item *list, int *len, const char *name);
void add_dep(item it, int i);
int parse_input(item *ret);
int get_depth(item list, int idx, int bad);
int main();

char input[] =
	"des_system_lib   std synopsys std_cell_lib des_system_lib dw02 dw01 ramlib ieee\n"
	"dw01             ieee dw01 dware gtech\n"
	"dw02             ieee dw02 dware\n"
	"dw03             std synopsys dware dw03 dw02 dw01 ieee gtech\n"
	"dw04             dw04 ieee dw01 dware gtech\n"
	"dw05             dw05 ieee dware\n"
	"dw06             dw06 ieee dware\n"
	"dw07             ieee dware\n"
	"dware            ieee dware\n"
	"gtech            ieee gtech\n"
	"ramlib           std ieee\n"
	"std_cell_lib     ieee std_cell_lib\n"
	"synopsys\n"
	"cycle_11	  cycle_12\n"
	"cycle_12	  cycle_11\n"
	"cycle_21	  dw01 cycle_22 dw02 dw03\n"
	"cycle_22	  cycle_21 dw01 dw04";
 
typedef struct item_t item_t, *item;
struct item_t { const char *name; int *deps, n_deps, idx, depth; };
 
int main()
{
	int i, j, n, bad = -1, max, min;
	item items;
	n = parse_input(&items);
 
	for (i = 0; i < n; i++)
		if (!items[i].depth && get_depth(items, i, bad) < 0) bad--;
 
	for (i = 0, max = min = 0; i < n; i++) {
		if (items[i].depth > max) max = items[i].depth;
		if (items[i].depth < min) min = items[i].depth;
	}
 
	printf("Compile order:\n");
	for (i = min; i <= max; i++) {
		if (!i) continue;
 
		if (i < 0) printf("   [unorderable]");
		else	   printf("%d:", i);
 
		for (j = 0; j < n || !putchar('\n'); j++)
			if (items[j].depth == i)
				printf(" %s", items[j].name);
	}
 
	return 0;
}
 
int get_depth(item list, int idx, int bad)
{
	int max, i, t;
 
	if (!list[idx].deps)
		return list[idx].depth = 1;
 
	if ((t = list[idx].depth) < 0) return t;
 
	list[idx].depth = bad;
	for (max = i = 0; i < list[idx].n_deps; i++) {
		if ((t = get_depth(list, list[idx].deps[i], bad)) < 0) {
			max = t;
			break;
		}
		if (max < t + 1) max = t + 1;
	}
	return list[idx].depth = max;
}
 
int parse_input(item *ret)
{
	int n_items = 0;
	int i, parent, idx;
	item list = 0;
 
	char *s, *e, *word, *we;
	for (s = input; ; s = 0) {
		if (!(s = strtok_r(s, "\n", &e))) break;
 
		for (i = 0, word = s; ; i++, word = 0) {
			if (!(word = strtok_r(word, " \t", &we))) break;
			idx = get_item(&list, &n_items, word);
 
			if (!i) parent = idx;
			else    add_dep(list + parent, idx);
		}
	}
 
	*ret = list;
	return n_items;
}
 
void add_dep(item it, int i)
{
	if (it->idx == i) return;
	it->deps = realloc(it->deps, (it->n_deps + 1) * sizeof(int));
	it->deps[it->n_deps++] = i;
}
 
int get_item(item *list, int *len, const char *name)
{
	int i;
	item lst = *list;
 
	for (i = 0; i < *len; i++)
		if (!strcmp(lst[i].name, name)) return i;
 
	lst = *list = realloc(lst, ++*len * sizeof(item_t));
	i = *len - 1;
	memset(lst + i, 0, sizeof(item_t));
	lst[i].idx = i;
	lst[i].name = name;
	return i;
}


                     bounds/toposort-shuf-2.c


#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
 
int get_item(item *list, int *len, const char *name);
void add_dep(item it, int i);
int parse_input(item *ret);
int get_depth(item list, int idx, int bad);
int main();

char input[] =
	"des_system_lib   std synopsys std_cell_lib des_system_lib dw02 dw01 ramlib ieee\n"
	"dw01             ieee dw01 dware gtech\n"
	"dw02             ieee dw02 dware\n"
	"dw03             std synopsys dware dw03 dw02 dw01 ieee gtech\n"
	"dw04             dw04 ieee dw01 dware gtech\n"
	"dw05             dw05 ieee dware\n"
	"dw06             dw06 ieee dware\n"
	"dw07             ieee dware\n"
	"dware            ieee dware\n"
	"gtech            ieee gtech\n"
	"ramlib           std ieee\n"
	"std_cell_lib     ieee std_cell_lib\n"
	"synopsys\n"
	"cycle_11	  cycle_12\n"
	"cycle_12	  cycle_11\n"
	"cycle_21	  dw01 cycle_22 dw02 dw03\n"
	"cycle_22	  cycle_21 dw01 dw04";
 
typedef struct item_t item_t, *item;
struct item_t { const char *name; int *deps, n_deps, idx, depth; };
 
int get_depth(item list, int idx, int bad)
{
	int max, i, t;
 
	if (!list[idx].deps)
		return list[idx].depth = 1;
 
	if ((t = list[idx].depth) < 0) return t;
 
	list[idx].depth = bad;
	for (max = i = 0; i < list[idx].n_deps; i++) {
		if ((t = get_depth(list, list[idx].deps[i], bad)) < 0) {
			max = t;
			break;
		}
		if (max < t + 1) max = t + 1;
	}
	return list[idx].depth = max;
}
 
int main()
{
	int i, j, n, bad = -1, max, min;
	item items;
	n = parse_input(&items);
 
	for (i = 0; i < n; i++)
		if (!items[i].depth && get_depth(items, i, bad) < 0) bad--;
 
	for (i = 0, max = min = 0; i < n; i++) {
		if (items[i].depth > max) max = items[i].depth;
		if (items[i].depth < min) min = items[i].depth;
	}
 
	printf("Compile order:\n");
	for (i = min; i <= max; i++) {
		if (!i) continue;
 
		if (i < 0) printf("   [unorderable]");
		else	   printf("%d:", i);
 
		for (j = 0; j < n || !putchar('\n'); j++)
			if (items[j].depth == i)
				printf(" %s", items[j].name);
	}
 
	return 0;
}
 
void add_dep(item it, int i)
{
	if (it->idx == i) return;
	it->deps = realloc(it->deps, (it->n_deps + 1) * sizeof(int));
	it->deps[it->n_deps++] = i;
}
 
int parse_input(item *ret)
{
	int n_items = 0;
	int i, parent, idx;
	item list = 0;
 
	char *s, *e, *word, *we;
	for (s = input; ; s = 0) {
		if (!(s = strtok_r(s, "\n", &e))) break;
 
		for (i = 0, word = s; ; i++, word = 0) {
			if (!(word = strtok_r(word, " \t", &we))) break;
			idx = get_item(&list, &n_items, word);
 
			if (!i) parent = idx;
			else    add_dep(list + parent, idx);
		}
	}
 
	*ret = list;
	return n_items;
}
 
int get_item(item *list, int *len, const char *name)
{
	int i;
	item lst = *list;
 
	for (i = 0; i < *len; i++)
		if (!strcmp(lst[i].name, name)) return i;
 
	lst = *list = realloc(lst, ++*len * sizeof(item_t));
	i = *len - 1;
	memset(lst + i, 0, sizeof(item_t));
	lst[i].idx = i;
	lst[i].name = name;
	return i;
}


                     bounds/toposort-shuf-3.c


#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
 
int get_item(item *list, int *len, const char *name);
void add_dep(item it, int i);
int parse_input(item *ret);
int get_depth(item list, int idx, int bad);
int main();

char input[] =
	"des_system_lib   std synopsys std_cell_lib des_system_lib dw02 dw01 ramlib ieee\n"
	"dw01             ieee dw01 dware gtech\n"
	"dw02             ieee dw02 dware\n"
	"dw03             std synopsys dware dw03 dw02 dw01 ieee gtech\n"
	"dw04             dw04 ieee dw01 dware gtech\n"
	"dw05             dw05 ieee dware\n"
	"dw06             dw06 ieee dware\n"
	"dw07             ieee dware\n"
	"dware            ieee dware\n"
	"gtech            ieee gtech\n"
	"ramlib           std ieee\n"
	"std_cell_lib     ieee std_cell_lib\n"
	"synopsys\n"
	"cycle_11	  cycle_12\n"
	"cycle_12	  cycle_11\n"
	"cycle_21	  dw01 cycle_22 dw02 dw03\n"
	"cycle_22	  cycle_21 dw01 dw04";
 
typedef struct item_t item_t, *item;
struct item_t { const char *name; int *deps, n_deps, idx, depth; };
 
int main()
{
	int i, j, n, bad = -1, max, min;
	item items;
	n = parse_input(&items);
 
	for (i = 0; i < n; i++)
		if (!items[i].depth && get_depth(items, i, bad) < 0) bad--;
 
	for (i = 0, max = min = 0; i < n; i++) {
		if (items[i].depth > max) max = items[i].depth;
		if (items[i].depth < min) min = items[i].depth;
	}
 
	printf("Compile order:\n");
	for (i = min; i <= max; i++) {
		if (!i) continue;
 
		if (i < 0) printf("   [unorderable]");
		else	   printf("%d:", i);
 
		for (j = 0; j < n || !putchar('\n'); j++)
			if (items[j].depth == i)
				printf(" %s", items[j].name);
	}
 
	return 0;
}
 
void add_dep(item it, int i)
{
	if (it->idx == i) return;
	it->deps = realloc(it->deps, (it->n_deps + 1) * sizeof(int));
	it->deps[it->n_deps++] = i;
}
 
int get_depth(item list, int idx, int bad)
{
	int max, i, t;
 
	if (!list[idx].deps)
		return list[idx].depth = 1;
 
	if ((t = list[idx].depth) < 0) return t;
 
	list[idx].depth = bad;
	for (max = i = 0; i < list[idx].n_deps; i++) {
		if ((t = get_depth(list, list[idx].deps[i], bad)) < 0) {
			max = t;
			break;
		}
		if (max < t + 1) max = t + 1;
	}
	return list[idx].depth = max;
}
 
int get_item(item *list, int *len, const char *name)
{
	int i;
	item lst = *list;
 
	for (i = 0; i < *len; i++)
		if (!strcmp(lst[i].name, name)) return i;
 
	lst = *list = realloc(lst, ++*len * sizeof(item_t));
	i = *len - 1;
	memset(lst + i, 0, sizeof(item_t));
	lst[i].idx = i;
	lst[i].name = name;
	return i;
}
 
int parse_input(item *ret)
{
	int n_items = 0;
	int i, parent, idx;
	item list = 0;
 
	char *s, *e, *word, *we;
	for (s = input; ; s = 0) {
		if (!(s = strtok_r(s, "\n", &e))) break;
 
		for (i = 0, word = s; ; i++, word = 0) {
			if (!(word = strtok_r(word, " \t", &we))) break;
			idx = get_item(&list, &n_items, word);
 
			if (!i) parent = idx;
			else    add_dep(list + parent, idx);
		}
	}
 
	*ret = list;
	return n_items;
}


                       samples/ackermann.c


int ackermann(int m, int n)
{
        if (!m) return n + 1;
        if (!n) return ackermann(m - 1, 1);
        return ackermann(m - 1, ackermann(m, n - 1));
}


                      samples/ackermann.cpp


unsigned int ackermann(unsigned int m, unsigned int n) {
  if (m == 0) {
    return n + 1;
  }
  if (n == 0) {
    return ackermann(m - 1, 1);
  }
  return ackermann(m - 1, ackermann(m, n - 1));
}


                      samples/ackermann.f90


  RECURSIVE FUNCTION Ackermann(m, n) RESULT(ack)
    INTEGER :: ack, m, n
 
    IF (m == 0) THEN
      ack = n + 1
    ELSE IF (n == 0) THEN
      ack = Ackermann(m - 1, 1)
    ELSE
      ack = Ackermann(m - 1, Ackermann(m, n - 1))
    END IF
  END FUNCTION Ackermann


                       samples/ackermann.hs


ack :: Int -> Int -> Int
ack 0 n = succ n
ack m 0 = ack (pred m) 1
ack m n = ack (pred m) (ack m (pred n))


                         samples/hello.c


#include <stdio.h>

int main() {
	puts("Hello!");
}


                        samples/hello.cpp


#include <iostream>

using namespace std;

int main() {
   cout << "Hello" << endl;
}


                        samples/hello.f90


program hello
  implicit none
  write(*,*) 'Hello'
end program hello


                         samples/hello.hs


main = putStrLn("Hello")


                        samples/ode-1_1.py


import numpy as np

from scipy.integrate import solve_ivp

ode_fn = lambda t, x: np.sin(t) + 3. * np.cos(2. * t) - x

t_begin=0.
t_end=10.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = 0.

method = 'RK45'
num_sol = solve_ivp(ode_fn, [t_begin, t_end], [x_init], method=method, dense_output=True)
x_num_sol = num_sol.sol(t_space).T


                        samples/ode-1_2.py


import numpy as np

import tensorflow as tf
import tensorflow_probability as tfp

ode_fn = lambda t, x: tf.math.sin(t) + tf.constant(3.) * tf.math.cos(tf.constant(2.) * t) - x

t_begin=0.
t_end=10.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
t_init = tf.constant(t_begin)
x_init = tf.constant(0.)

num_sol = tfp.math.ode.BDF().solve(ode_fn, t_init, x_init,
	solution_times=tfp.math.ode.ChosenBySolver(tf.constant(t_end)) )


                        samples/ode-1_3.py


import numpy as np

import torch
from torchdiffeq import odeint

ode_fn = lambda t, x: torch.sin(t) + 3. * torch.cos(2. * t) - x

t_begin=0.
t_end=10.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = torch.tensor([0.])

x_num_sol = odeint(ode_fn, x_init, torch.tensor(t_space))


                        samples/ode-1_4.py


import numpy as np

import tensorflow as tf
from tfdiffeq import odeint

ode_fn = lambda t, x: tf.math.sin(t) + 3. * tf.math.cos(2. * t) - x

t_begin=0.
t_end=10.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = tf.constant([0.])

x_num_sol = odeint(ode_fn, x_init, tf.constant(t_space))


                        samples/ode-1_5.py


import numpy as np
import torch

from neurodiffeq import diff
from neurodiffeq.ode import solve
from neurodiffeq.ode import IVP
from neurodiffeq.ode import Monitor
import neurodiffeq.networks as ndenw

ode_fn = lambda x, t: diff(x, t, order=1) + x - torch.sin(t) - 3. * torch.cos(2. * t)

t_begin=0.
t_end=2.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = IVP(t_0=t_begin, x_0=0.0)

net = ndenw.FCNN(n_hidden_layers=6, n_hidden_units=50, actv=torch.nn.Tanh)
optimizer = torch.optim.SGD(net.parameters(), lr=0.001)
num_sol, loss_sol = solve(ode_fn, x_init, t_min=t_begin, t_max=t_end,
	batch_size=30,
	max_epochs=1000,
	return_best=True,
	net=net,
	optimizer=optimizer,
	monitor=Monitor(t_min=t_begin, t_max=t_end, check_every=10))
x_num_sol = num_sol(t_space, as_type='np')


                         samples/ode-1.jl


using DifferentialEquations

ode_fn(x,p,t) = sin(t) + 3.0 * cos(2.0 * t) - x

t_begin=0.0
t_end=10.0
tspan = (t_begin,t_end)
x_init=0.0

prob = ODEProblem(ode_fn, x_init, tspan)
num_sol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)


                        samples/ode-1.txt


ode_fn(x,p,t) = sin(t) + 3.0 * cos(2.0 * t) - x


                        samples/ode-2_1.py


import numpy as np

from scipy.integrate import solve_ivp

def ode_sys(t, XY):
	x=XY[0]
	y=XY[1]
	dx_dt= - x + y
	dy_dt= 4. * x - y
	return [dx_dt, dy_dt]

t_begin=0.
t_end=5.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = 2.
y_init = 0.

method = 'RK45'
num_sol = solve_ivp(ode_sys, [t_begin, t_end], [x_init, y_init], method=method, dense_output=True)
XY_num_sol = num_sol.sol(t_space)
x_num_sol = XY_num_sol[0].T
y_num_sol = XY_num_sol[1].T


                        samples/ode-2_2.py


import numpy as np

import tensorflow as tf
import tensorflow_probability as tfp

def ode_sys(t, XY):
	x=XY[0]
	y=XY[1]
	dx_dt= - x + y
	dy_dt= 4. * x - y
	return [dx_dt, dy_dt]

t_begin=0.
t_end=5.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
t_init = tf.constant(t_begin)
x_init = tf.constant(2.)
y_init = tf.constant(0.)

num_sol = tfp.math.ode.BDF().solve(ode_sys, t_init, [x_init, y_init],
	solution_times=tfp.math.ode.ChosenBySolver(tf.constant(t_end)) )


                        samples/ode-2_3.py


import numpy as np

import torch
from torchdiffeq import odeint

def ode_sys(t, XY):
	x=XY[0]
	y=XY[1]
	dx_dt= torch.Tensor([- x + y])
	dy_dt= torch.Tensor([4. * x - y])
	return torch.cat([dx_dt, dy_dt])

t_begin=0.
t_end=5.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = torch.Tensor([2.])
y_init = torch.Tensor([0.])

num_sol = odeint(ode_sys, torch.cat([x_init, y_init]), torch.Tensor(t_space)).numpy()



                        samples/ode-2_4.py


import numpy as np

import tensorflow as tf
from tfdiffeq import odeint

def ode_sys(t, XY):
	x=XY[0]
	y=XY[1]
	dx_dt= - x + y
	dy_dt= 4. * x - y
	return tf.stack([dx_dt, dy_dt])

t_begin=0.
t_end=5.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = tf.constant([2.])
y_init = tf.constant([0.])

num_sol = odeint(
    ode_sys, 
    tf.convert_to_tensor([x_init, y_init], dtype=tf.float64), 
    tf.constant(t_space)).numpy()


                        samples/ode-2_5.py


import numpy as np
import torch

from neurodiffeq import diff
from neurodiffeq.ode import solve_system
from neurodiffeq.ode import IVP
from neurodiffeq.ode import Monitor
import neurodiffeq.networks as ndenw

ode_sys = lambda x, y, t: [diff(x, t, order=1) + x - y, diff(y, t, order=1) - 4. * x + y ]

t_begin=0.
t_end=2.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = IVP(t_0=t_begin, x_0=2.0)
y_init = IVP(t_0=t_begin, x_0=0.0)

batch_size=200

net = ndenw.FCNN(
	n_input_units=1,
        n_output_units=2,
	n_hidden_layers=3, 
	n_hidden_units=50, 
	actv=ndenw.SinActv)

optimizer = torch.optim.Adam(net.parameters(), lr=0.003)
 
num_sol, history = solve_system(
	ode_system=ode_sys,
	conditions=[x_init, y_init], 
	t_min=t_begin, 
	t_max=t_end,
	batch_size=batch_size,
	max_epochs=1200,
	return_best=True,
	single_net = net,
	optimizer=optimizer,
	monitor=Monitor(t_min=t_begin, t_max=t_end, check_every=10))
num_sol = num_sol(t_space, as_type='np')


                         samples/ode-2.jl


using StaticArrays
using DifferentialEquations

A = @SMatrix [-1.0 1.0
              4.0 -1.0]

function ode_fn(du,u,p,t)
    du[[true, true]] = A * u
end

t_begin=0.0
t_end=5
tspan = (t_begin,t_end)
x_init=2.0
y_init=0.0

prob = ODEProblem(ode_fn, [x_init, y_init], tspan)
num_sol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)
x_num_sol = [u[1] for u in num_sol.u]
y_num_sol = [u[2] for u in num_sol.u]


                        samples/ode-2.txt


function ode_fn(du,u,p,t)
    x, y = u
    du[1] = y - x
    du[2] = 4.0 * x - y
end


                        samples/ode-3_1.py


import numpy as np

from scipy.integrate import solve_ivp

def ode_sys(t, X):
	x=X[0]
	dx_dt=X[1]
	d2x_dt2=-dx_dt - 2*x
	return [dx_dt, d2x_dt2]

t_begin=0.
t_end=12.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = 1.
dxdt_init = 0.

method = 'RK45'
num_sol = solve_ivp(ode_sys, [t_begin, t_end], [x_init, dxdt_init], method=method, dense_output=True)
X_num_sol = num_sol.sol(t_space)
x_num_sol = X_num_sol[0].T


                        samples/ode-3_2.py


import numpy as np

import tensorflow as tf
import tensorflow_probability as tfp

def ode_sys(t, X):
	x=X[0]
	dx_dt=X[1]
	d2x_dt2=-dx_dt - 2*x
	return [dx_dt, d2x_dt2]

t_begin=0.
t_end=12.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
t_init = tf.constant(t_begin)
x_init = tf.constant(1.)
dxdt_init = tf.constant(0.)

num_sol = tfp.math.ode.BDF().solve(ode_sys, t_init, [x_init, dxdt_init],
	solution_times=tfp.math.ode.ChosenBySolver(tf.constant(t_end)) )


                        samples/ode-3_3.py


import numpy as np

import torch
from torchdiffeq import odeint

def ode_sys(t, X):
	x=torch.Tensor([X[0]])
	dx_dt=torch.Tensor([X[1]])
	d2x_dt2=torch.Tensor([-dx_dt - 2*x])
	return torch.cat([dx_dt, d2x_dt2])

t_begin=0.
t_end=12.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = torch.Tensor([1.])
dxdt_init = torch.Tensor([0.])

num_sol = odeint(ode_sys, torch.cat([x_init, dxdt_init]), torch.Tensor(t_space)).numpy()


                        samples/ode-3_4.py


import numpy as np

import tensorflow as tf
from tfdiffeq import odeint

def ode_sys(t, X):
	x=X[0]
	dx_dt=X[1]
	d2x_dt2=-dx_dt - 2*x
	return tf.stack([dx_dt, d2x_dt2])

t_begin=0.
t_end=12.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = tf.constant([1.])
dxdt_init = tf.constant([0.])

num_sol = odeint(
	ode_sys, 
	tf.convert_to_tensor([x_init, dxdt_init], dtype=tf.float64), 
	tf.constant(t_space)).numpy()


                        samples/ode-3_5.py


import numpy as np
import torch

from neurodiffeq import diff
from neurodiffeq.ode import solve
from neurodiffeq.ode import IVP
from neurodiffeq.ode import Monitor
import neurodiffeq.networks as ndenw

ode_fn = lambda x, t: diff(x, t, order=1) + x - torch.sin(t) - 3. * torch.cos(2. * t)

t_begin=0.
t_end=2.
t_nsamples=100
t_space = np.linspace(t_begin, t_end, t_nsamples)
x_init = IVP(t_0=t_begin, x_0=0.0)

net = ndenw.FCNN(n_hidden_layers=6, n_hidden_units=50, actv=torch.nn.Tanh)
optimizer = torch.optim.SGD(net.parameters(), lr=0.001)
num_sol, loss_sol = solve(ode_fn, x_init, t_min=t_begin, t_max=t_end,
	batch_size=30,
	max_epochs=1000,
	return_best=True,
	net=net,
	optimizer=optimizer,
	monitor=Monitor(t_min=t_begin, t_max=t_end, check_every=10))
x_num_sol = num_sol(t_space, as_type='np')


                         samples/ode-3.jl


using DifferentialEquations

function ode_fn(dx,x,p,t)
    -dx -2.0 * x
end

t_begin=0.0
t_end=12.0
tspan = (t_begin,t_end)
x_init=1.0
dxdt_init=0.0

prob = SecondOrderODEProblem(ode_fn, dxdt_init, x_init, tspan)
num_sol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)
x_num_sol = [u[2] for u in num_sol.u]


                        samples/ode-3.txt


function ode_fn(dx,x,p,t)
    -dx -2.0 * x
end


                       samples/quicksort.c


void quicksort(int *A, int len) {
  if (len < 2) return;
 
  int pivot = A[len / 2];
 
  int i, j;
  for (i = 0, j = len - 1; ; i++, j--) {
    while (A[i] < pivot) i++;
    while (A[j] > pivot) j--;
 
    if (i >= j) break;
 
    int temp = A[i];
    A[i]     = A[j];
    A[j]     = temp;
  }
 
  quicksort(A, i);
  quicksort(A + i, len - i);
}


                      samples/quicksort.cpp


#include <iterator>
#include <algorithm>
#include <functional>
 
template<typename RandomAccessIterator,
         typename Order>
 void quicksort(RandomAccessIterator first, RandomAccessIterator last, Order order)
{
  if (last - first > 1)
  {
    RandomAccessIterator split = std::partition(first+1, last, std::bind2nd(order, *first));
    std::iter_swap(first, split-1);
    quicksort(first, split-1, order);
    quicksort(split, last, order);
  }
}
 
template<typename RandomAccessIterator>
 void quicksort(RandomAccessIterator first, RandomAccessIterator last)
{
  quicksort(first, last, std::less<typename std::iterator_traits<RandomAccessIterator>::value_type>());
}


                      samples/quicksort.f90


MODULE qsort_mod
 
  IMPLICIT NONE
 
  TYPE group
     INTEGER :: order
     REAL    :: VALUE
  END TYPE group
 
CONTAINS
 
  RECURSIVE SUBROUTINE QSort(a,na)
 
    INTEGER, INTENT(in) :: nA
    TYPE (group), DIMENSION(nA), INTENT(in out) :: A
 
    INTEGER :: left, right
    REAL :: random
    REAL :: pivot
    TYPE (group) :: temp
    INTEGER :: marker
 
    IF (nA > 1) THEN
 
       CALL random_NUMBER(random)
       pivot = A(INT(random*REAL(nA-1))+1)%VALUE
       left = 1
       right = nA
       DO
          IF (left >= right) EXIT
          DO
             IF (A(right)%VALUE <= pivot) EXIT
             right = right - 1
          END DO
          DO
             IF (A(left)%VALUE >= pivot) EXIT
             left = left + 1
          END DO
          IF (left < right) THEN
             temp = A(left)
             A(left) = A(right)
             A(right) = temp
          END IF
       END DO
 
       IF (left == right) THEN
          marker = left + 1
       ELSE
          marker = left
       END IF
 
       CALL QSort(A(:marker-1),marker-1)
       CALL QSort(A(marker:),nA-marker+1)
 
    END IF
 
  END SUBROUTINE QSort
 
END MODULE qsort_mod


                       samples/quicksort.hs


qsort [] = []
qsort (x:xs) = qsort [y | y <- xs, y < x] ++ [x] ++ qsort [y | y <- xs, y >= x]


                        samples/toposort.c


#include <stdlib.h>
#include <string.h>
#include <ctype.h>
 
typedef struct item_t item_t, *item;
struct item_t { const char *name; int *deps, n_deps, idx, depth; };
 
int get_item(item *list, int *len, const char *name)
{
	int i;
	item lst = *list;
 
	for (i = 0; i < *len; i++)
		if (!strcmp(lst[i].name, name)) return i;
 
	lst = *list = realloc(lst, ++*len * sizeof(item_t));
	i = *len - 1;
	memset(lst + i, 0, sizeof(item_t));
	lst[i].idx = i;
	lst[i].name = name;
	return i;
}
 
void add_dep(item it, int i)
{
	if (it->idx == i) return;
	it->deps = realloc(it->deps, (it->n_deps + 1) * sizeof(int));
	it->deps[it->n_deps++] = i;
}
 
int get_depth(item list, int idx, int bad)
{
	int max, i, t;
 
	if (!list[idx].deps)
		return list[idx].depth = 1;
 
	if ((t = list[idx].depth) < 0) return t;
 
	list[idx].depth = bad;
	for (max = i = 0; i < list[idx].n_deps; i++) {
		if ((t = get_depth(list, list[idx].deps[i], bad)) < 0) {
			max = t;
			break;
		}
		if (max < t + 1) max = t + 1;
	}
	return list[idx].depth = max;
}

int toposort(item items)
{
	int i, j, n, bad = -1, max, min;
 
	for (i = 0; i < n; i++)
		if (!items[i].depth && get_depth(items, i, bad) < 0) bad--;
 
	for (i = 0, max = min = 0; i < n; i++) {
		if (items[i].depth > max) max = items[i].depth;
		if (items[i].depth < min) min = items[i].depth;
	}
 
	return 0;
}


                       samples/toposort.cpp


#include <map>
#include <set>
 
template<typename Goal>
class topological_sorter {
protected:
    struct relations {
        std::size_t dependencies;
        std::set<Goal> dependents;
    };
    std::map<Goal, relations> map;
public:
    void add_goal(Goal const &goal) {
        map[goal];
    }
    void add_dependency(Goal const &goal, Goal const &dependency) {
        if (dependency == goal)
            return;
        auto &dependents = map[dependency].dependents;
        if (dependents.find(goal) == dependents.end()) {
            dependents.insert(goal);
            ++map[goal].dependencies;
        }
    }
    template<typename Container>
    void add_dependencies(Goal const &goal, Container const &dependencies) {
        for (auto const &dependency : dependencies)
            add_dependency(goal, dependency);
    }
    template<typename ResultContainer, typename CyclicContainer>
    void destructive_sort(ResultContainer &sorted, CyclicContainer &unsortable) {
        sorted.clear();
        unsortable.clear();
        for (auto const &lookup : map) {
            auto const &goal = lookup.first;
            auto const &relations = lookup.second;
            if (relations.dependencies == 0)
                sorted.push_back(goal);
        }
        for (std::size_t index = 0; index < sorted.size(); ++index)
            for (auto const &goal : map[sorted[index]].dependents)
                if (--map[goal].dependencies == 0)
                    sorted.push_back(goal);
        for (auto const &lookup : map) {
            auto const &goal = lookup.first;
            auto const &relations = lookup.second;
            if (relations.dependencies != 0)
                unsortable.push_back(goal);
        }
    }
    template<typename ResultContainer, typename CyclicContainer>
    void sort(ResultContainer &sorted, CyclicContainer &unsortable) {
        topological_sorter<Goal> temporary = *this;
        temporary.destructive_sort(sorted, unsortable);
    }
    void clear() {
        map.clear();
    }
};


                       samples/toposort.f90


subroutine tsort(nl,nd,idep,iord,no)
 
  implicit none
 
  integer,intent(in) :: nl
  integer,intent(in) :: nd
  integer,dimension(nd,2),intent(in) :: idep
  integer,dimension(nl),intent(out) :: iord
  integer,intent(out) :: no
 
  integer :: i,j,k,il,ir,ipl,ipr,ipos(nl)
 
  do i=1,nl
    iord(i)=i
    ipos(i)=i
  end do
  k=1
  do
    j=k
    k=nl+1
    do i=1,nd
      il=idep(i,1)
      ir=idep(i,2)
      ipl=ipos(il)
      ipr=ipos(ir)
      if (il==ir .or. ipl>=k .or. ipl<j .or. ipr<j) cycle
      k=k-1
      ipos(iord(k))=ipl
      ipos(il)=k
      iord(ipl)=iord(k)
      iord(k)=il
    end do
    if (k<=j) exit
  end do
  no=j-1
 
end subroutine tsort


                       samples/toposort.hs


import Data.List ((\\), elemIndex, intersect, nub)
import Data.Bifunctor (bimap, first)
 
combs 0 _ = [[]]
combs _ [] = []
combs k (x:xs) = ((x :) <$> combs (k - 1) xs) ++ combs k xs
 
toposort :: [(String, String)] -> [String]
toposort xs
  | (not . null) cycleDetect =
    error $ "Dependency cycle detected for libs " ++ show cycleDetect
  | otherwise = foldl makePrecede [] dB
  where
    dB = (\(x, y) -> (x, y \\ x)) . bimap return words <$> xs
    makePrecede ts ([x], xs) =
      nub $
      case elemIndex x ts of
        Just i -> uncurry (++) $ first (++ xs) $ splitAt i ts
        _ -> ts ++ xs ++ [x]
    cycleDetect =
      filter ((> 1) . length) $
      (\[(a, as), (b, bs)] -> (a `intersect` bs) ++ (b `intersect` as)) <$>
      combs 2 dB
```
